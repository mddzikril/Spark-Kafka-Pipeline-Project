#spark conf
[LOCAL]
spark.app.name = spark-project-local
spark.sql.shuffle.partitions = 5
spark.jars.packages = org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.4
[QA]
spark.app.name = spark-project-qa
spark.jars.packages = org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.4
spark.executor.instances = 160
spark.executor.cores = 5
spark.executor.memory = 10G
spark.executor.memoryOverhead = 1GB
spark.sql.shuffle.partitions = 800
[PROD]
spark.app.name = spark-project-prod
spark.jars.packages = org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.4
spark.executor.instances = 160
spark.executor.cores = 5
spark.executor.memory = 10G
spark.executor.memoryOverhead = 1GB
spark.sql.shuffle.partitions = 800